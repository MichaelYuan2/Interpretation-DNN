{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import logging\n",
    "from math import sqrt, ceil\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from create_dataset import *\n",
    "from MCAgent import MCAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_label(array):\n",
    "    label = np.full(169, \" \", dtype=\"S6\")\n",
    "    p = 0\n",
    "    for i in range(18):\n",
    "        for j in range(i+1, 18):\n",
    "            if array[j] != 0:\n",
    "                # print(label[p].dtype)\n",
    "                label[p] = \"X{}/X{}\".format(i+1, j+1)\n",
    "                p+=1\n",
    "    label = label.reshape(13, 13)\n",
    "    return label\n",
    "\n",
    "# array_to_label(np.ones(169)).reshape(-1)[:153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_processing(df):\n",
    "    # Find the oldest year for each company\n",
    "    oldest_years = df.groupby('company_name')['year'].min()\n",
    "    \n",
    "    # Filter companies that are alive in the oldest year\n",
    "    df = pd.merge(df, oldest_years, on=['company_name', 'year' ], how='inner')\n",
    "    df = df[(df['status_label'] == 1)]\n",
    "    df = df.drop(columns=['company_name', 'status_label', 'year'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data path\n",
    "DATAPATH = r'american_bankruptcy.csv'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "df_raw = load_data(DATAPATH)\n",
    "df = df_processing(df_raw)\n",
    "# df.to_csv(\"Processed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratios_dataframe(df):\n",
    "    # convert the dataframe to ratios\n",
    "    ratios_df = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].replace(0, 1e-6)\n",
    "    for i in range(18):\n",
    "        for j in range(i+1, 18):\n",
    "            column = \"X{}/X{}\".format(i+1, j+1)\n",
    "            ratios_df[column] = df[\"X{}\".format(i+1)] / df[\"X{}\".format(j+1)]\n",
    "            ratios_df[column] = (ratios_df[column] - ratios_df[column].mean()) / ratios_df[column].std() + 128\n",
    "    # ratios_df['status_label'] = df['status_label']\n",
    "    return ratios_df\n",
    "\n",
    "# df = df.drop(columns=['status_label'])\n",
    "ratios_df = ratios_dataframe(df_raw)\n",
    "print(ratios_df.head())\n",
    "# print(ratios_df['X1/X2'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = array_to_label(np.ones(169))\n",
    "print(labels.shape)\n",
    "\n",
    "mc_agent = MCAgent(ratios_df, labels)\n",
    "new_labels, pixels = mc_agent.monte_carlo_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_image(image_array, new_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Enlarge an 13x13 image and a corresponding 13x13 dataframe to 64x64 using nearest neighbor method.\n",
    "\n",
    "    Args:\n",
    "    image_array (numpy.ndarray): An 13x13 numpy array representing the image.\n",
    "    new_size (tuple): New size for the image and dataframe, default is (64, 64).\n",
    "\n",
    "    Returns:\n",
    "    numpy array: a numpy array of the enlarged image\n",
    "    \"\"\"\n",
    "    if image_array.shape != (13, 13):\n",
    "        raise ValueError(\"Input image array and dataframe must be 13x13 in size.\")\n",
    "\n",
    "    # Enlarge the image array\n",
    "    image_pil = Image.fromarray(image_array)\n",
    "    enlarged_image_pil = image_pil.resize(new_size, Image.NEAREST)\n",
    "    enlarged_image_array = np.array(enlarged_image_pil)\n",
    "\n",
    "    return enlarged_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_image(image, pixels):\n",
    "    image = image.reshape(-1)\n",
    "    new_image = np.zeros(image.size)\n",
    "    for i, pixel in enumerate(pixels):\n",
    "        new_image[i] = image[pixel]\n",
    "    return new_image.reshape(13, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"Processed_df.csv\")\n",
    "# Calculate the average based on the oldest year\n",
    "df_mean = pd.DataFrame(df.mean()).T\n",
    "data = df_mean.iloc[0].to_numpy()\n",
    "\n",
    "\n",
    "# print(df_raw.head())\n",
    "data_continue = df_raw[df_raw['status_label'] == 1].iloc[0].loc[\"X1\":].to_numpy()\n",
    "data_bankrupt= df_raw[df_raw['status_label'] == 0].iloc[1].loc[\"X1\":].to_numpy()\n",
    "# print(data_continue)\n",
    "# print(data_bankrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_continue = array_to_image(data_continue)\n",
    "image_continue_1 = enlarge_image(image_continue)\n",
    "# fig1 = array_to_grayscale_image(enlarged_image)\n",
    "\n",
    "image_bankrupt = array_to_image(data_bankrupt)\n",
    "image_bankrupt_1 = enlarge_image(image_bankrupt)\n",
    "# fig2 = array_to_grayscale_image(enlarged_image)\n",
    "\n",
    "image_continue = rearrange_image(image_continue, pixels)\n",
    "image_continue_2 = enlarge_image(image_continue)\n",
    "# fig = array_to_grayscale_image(enlarged_image)\n",
    "\n",
    "image_bankrupt = rearrange_image(image_bankrupt, pixels)\n",
    "image_bankrupt_2 = enlarge_image(image_bankrupt)\n",
    "print(image_bankrupt)\n",
    "# fig = array_to_grayscale_image(enlarged_image)\n",
    "\n",
    "# Convert arrays to grayscale images\n",
    "image_continue_1 = plt.cm.gray(image_continue_1)\n",
    "image_continue_2 = plt.cm.gray(image_continue_2)\n",
    "image_bankrupt_1 = plt.cm.gray(image_bankrupt_1)\n",
    "image_bankrupt_2 = plt.cm.gray(image_bankrupt_2)\n",
    "\n",
    "# Create a (2, 2) subplot grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "# Display the images in the subplots\n",
    "axs[0, 0].imshow(image_continue_1)\n",
    "axs[0, 0].set_title('Continue 1')\n",
    "\n",
    "axs[1, 0].imshow(image_continue_2)\n",
    "axs[1, 0].set_title('Continue 2')\n",
    "\n",
    "axs[0, 1].imshow(image_bankrupt_1)\n",
    "axs[0, 1].set_title('Bankrupt 1')\n",
    "\n",
    "axs[1, 1].imshow(image_bankrupt_2)\n",
    "axs[1, 1].set_title('Bankrupt 2')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test for modified create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_dataset import create_dataset\n",
    "\n",
    "DATAPATH = r'american_bankruptcy.csv'\n",
    "\n",
    "bankrupt_data = load_data(DATAPATH)\n",
    "dataset = create_dataset(bankrupt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, s) in enumerate(dataset[:5]):\n",
    "    print(\"i:{}, status: {}\".format(i, s))\n",
    "    fig = array_to_grayscale_image(data.reshape(64, 64))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample the dataset (as we have an extremely unbalanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = r'american_bankruptcy.csv'\n",
    "bankrupt_data = load_data(DATAPATH) # this load_data is the version before modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X, y = bankrupt_data.drop(columns=['company_name', 'year', 'status_label']), bankrupt_data['status_label'] \n",
    "# print(X.head())\n",
    "print(\"Original dataset shape: %s\", Counter(y))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s', Counter(y_res))\n",
    "\n",
    "X_res['status_label'] = y_res\n",
    "print(X_res['status_label'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
